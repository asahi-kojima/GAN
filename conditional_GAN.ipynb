{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a12a8978",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torchvision.datasets import FashionMNIST\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d63c7f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "workers = 2\n",
    "batch_size=50\n",
    "nz = 100\n",
    "nch_g = 128\n",
    "nch_d = 128\n",
    "n_epoch = 50\n",
    "lr = 0.0002\n",
    "beta1 = 0.5\n",
    "outf = './result_cgan'\n",
    "display_interval = 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "866dc748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6889666",
   "metadata": {},
   "source": [
    "### MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7e37dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = FashionMNIST(root='./fashion_mnist_root', download = True, train = True,\n",
    "                      transform = transforms.Compose([\n",
    "                          transforms.ToTensor(),\n",
    "                          transforms.Normalize((0.5,), (0.5,)) ])) \n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size = batch_size, shuffle = True, num_workers = int(workers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b1dbbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, nz = 100,  nch_g = 64, nch = 1):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "                nn.ConvTranspose2d(nz, nch_g * 4, 3, 1, 0),    \n",
    "                nn.BatchNorm2d(nch_g * 4),                      \n",
    "                nn.ReLU(),\n",
    "                nn.ConvTranspose2d(nch_g * 4, nch_g * 2, 3, 2, 0),\n",
    "                nn.BatchNorm2d(nch_g * 2),\n",
    "                nn.ReLU(),\n",
    "                nn.ConvTranspose2d(nch_g * 2, nch_g, 4, 2, 1),\n",
    "                nn.BatchNorm2d(nch_g),\n",
    "                nn.ReLU(),\n",
    "                nn.ConvTranspose2d(nch_g, nch, 4, 2, 1),\n",
    "                nn.Tanh()\n",
    "                )\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.layers(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03c0ab23",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, nch=1, nch_d=64):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "                nn.Conv2d(nch, nch_d, 4, 2, 1),     # 畳み込み\n",
    "                nn.LeakyReLU(negative_slope=0.2),\n",
    "                nn.Conv2d(nch_d, nch_d * 2, 4, 2, 1),\n",
    "                nn.BatchNorm2d(nch_d * 2),\n",
    "                nn.LeakyReLU(negative_slope=0.2),\n",
    "                nn.Conv2d(nch_d * 2, nch_d * 4, 3, 2, 0),\n",
    "                nn.BatchNorm2d(nch_d * 4),\n",
    "                nn.LeakyReLU(negative_slope=0.2),\n",
    "                nn.Conv2d(nch_d * 4, 1, 3, 1, 0),\n",
    "                nn.Sigmoid()\n",
    "                ) \n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f86b85a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator(\n",
      "  (layers): Sequential(\n",
      "    (0): ConvTranspose2d(110, 512, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): ConvTranspose2d(512, 256, kernel_size=(3, 3), stride=(2, 2))\n",
      "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU()\n",
      "    (6): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (8): ReLU()\n",
      "    (9): ConvTranspose2d(128, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (10): Tanh()\n",
      "  )\n",
      ")\n",
      "Discriminator(\n",
      "  (layers): Sequential(\n",
      "    (0): Conv2d(11, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (1): LeakyReLU(negative_slope=0.2)\n",
      "    (2): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): LeakyReLU(negative_slope=0.2)\n",
      "    (5): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2))\n",
      "    (6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): LeakyReLU(negative_slope=0.2)\n",
      "    (8): Conv2d(512, 1, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (9): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "Gnet = Generator(nz = nz+10, nch_g = nch_g).to(device)\n",
    "Dnet = Discriminator(nch = 1+10, nch_d = nch_d).to(device)\n",
    "print(Gnet)\n",
    "print(Dnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6876b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizerD = optim.Adam(Dnet.parameters(), lr=lr, betas=(beta1, 0.999), weight_decay=1e-5)\n",
    "optimizerG = optim.Adam(Gnet.parameters(), lr=lr, betas=(beta1, 0.999), weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "860a0366",
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot_encode(label, device, n_class = 10):\n",
    "    eye = torch.eye(n_class, device = device)\n",
    "    return eye[label].view(-1, n_class, 1, 1) \n",
    "\n",
    "def concat_image_label(image, label, device, n_class=10):\n",
    "    B, C, H, W = image.shape\n",
    "    \n",
    "    oh_label = onehot_encode(label, device)\n",
    "    oh_label = oh_label.expand(B, n_class, H, W)\n",
    "    return torch.cat((image, oh_label), dim = 1)\n",
    "\n",
    "def concat_noise_label(noise, label, device):\n",
    "    oh_label = onehot_encode(label, device) \n",
    "    return torch.cat((noise, oh_label), dim = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4bad0b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 100, 1, 1])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3,\n",
      "        4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7,\n",
      "        8, 9], device='cuda:0')\n",
      "torch.Size([50, 110, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "fixed_noise = torch.randn(batch_size, nz, 1, 1, device=device)\n",
    "fixed_label = [i for i in range(10)] * (batch_size // 10)\n",
    "fixed_label = torch.tensor(fixed_label, dtype=torch.long, device=device)\n",
    "fixed_noise_label = concat_noise_label(fixed_noise, fixed_label, device) \n",
    "print(fixed_noise.shape)\n",
    "print(fixed_label)\n",
    "print(fixed_noise_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76985943",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(outf):\n",
    "    os.mkdir(outf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0aadfad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/50][1/1200] Loss_D: 1.501 Loss_G: 1.259 D(x): 0.408 D(G(z)): 0.436/0.291\n",
      "[1/50][601/1200] Loss_D: 0.663 Loss_G: 3.177 D(x): 0.901 D(G(z)): 0.391/0.064\n",
      "[2/50][1/1200] Loss_D: 0.713 Loss_G: 2.314 D(x): 0.727 D(G(z)): 0.290/0.133\n",
      "[2/50][601/1200] Loss_D: 0.992 Loss_G: 2.248 D(x): 0.767 D(G(z)): 0.462/0.143\n",
      "[3/50][1/1200] Loss_D: 0.886 Loss_G: 1.745 D(x): 0.687 D(G(z)): 0.346/0.202\n",
      "[3/50][601/1200] Loss_D: 0.884 Loss_G: 1.695 D(x): 0.667 D(G(z)): 0.323/0.215\n",
      "[4/50][1/1200] Loss_D: 0.950 Loss_G: 2.304 D(x): 0.819 D(G(z)): 0.476/0.128\n",
      "[4/50][601/1200] Loss_D: 0.795 Loss_G: 2.211 D(x): 0.659 D(G(z)): 0.242/0.140\n",
      "[5/50][1/1200] Loss_D: 1.473 Loss_G: 2.412 D(x): 0.764 D(G(z)): 0.626/0.129\n",
      "[5/50][601/1200] Loss_D: 1.086 Loss_G: 1.955 D(x): 0.698 D(G(z)): 0.426/0.172\n",
      "[6/50][1/1200] Loss_D: 0.583 Loss_G: 2.674 D(x): 0.787 D(G(z)): 0.244/0.090\n",
      "[6/50][601/1200] Loss_D: 0.787 Loss_G: 2.176 D(x): 0.749 D(G(z)): 0.344/0.150\n",
      "[7/50][1/1200] Loss_D: 0.656 Loss_G: 1.883 D(x): 0.793 D(G(z)): 0.314/0.172\n",
      "[7/50][601/1200] Loss_D: 0.567 Loss_G: 2.712 D(x): 0.848 D(G(z)): 0.298/0.089\n",
      "[8/50][1/1200] Loss_D: 0.900 Loss_G: 1.996 D(x): 0.648 D(G(z)): 0.251/0.186\n",
      "[8/50][601/1200] Loss_D: 1.322 Loss_G: 1.413 D(x): 0.373 D(G(z)): 0.062/0.293\n",
      "[9/50][1/1200] Loss_D: 0.578 Loss_G: 2.421 D(x): 0.705 D(G(z)): 0.123/0.112\n",
      "[9/50][601/1200] Loss_D: 0.694 Loss_G: 1.947 D(x): 0.650 D(G(z)): 0.181/0.162\n",
      "[10/50][1/1200] Loss_D: 0.517 Loss_G: 2.571 D(x): 0.818 D(G(z)): 0.231/0.095\n",
      "[10/50][601/1200] Loss_D: 0.538 Loss_G: 3.226 D(x): 0.859 D(G(z)): 0.282/0.051\n",
      "[11/50][1/1200] Loss_D: 0.576 Loss_G: 2.050 D(x): 0.689 D(G(z)): 0.119/0.171\n",
      "[11/50][601/1200] Loss_D: 0.730 Loss_G: 2.356 D(x): 0.637 D(G(z)): 0.137/0.137\n",
      "[12/50][1/1200] Loss_D: 0.682 Loss_G: 3.674 D(x): 0.900 D(G(z)): 0.396/0.034\n",
      "[12/50][601/1200] Loss_D: 0.706 Loss_G: 3.068 D(x): 0.917 D(G(z)): 0.410/0.058\n",
      "[13/50][1/1200] Loss_D: 0.923 Loss_G: 2.790 D(x): 0.750 D(G(z)): 0.361/0.100\n",
      "[13/50][601/1200] Loss_D: 0.696 Loss_G: 3.980 D(x): 0.753 D(G(z)): 0.270/0.027\n",
      "[14/50][1/1200] Loss_D: 0.476 Loss_G: 2.670 D(x): 0.782 D(G(z)): 0.149/0.096\n",
      "[14/50][601/1200] Loss_D: 0.556 Loss_G: 2.883 D(x): 0.771 D(G(z)): 0.193/0.082\n",
      "[15/50][1/1200] Loss_D: 0.998 Loss_G: 1.676 D(x): 0.482 D(G(z)): 0.076/0.279\n",
      "[15/50][601/1200] Loss_D: 0.960 Loss_G: 4.052 D(x): 0.962 D(G(z)): 0.493/0.030\n",
      "[16/50][1/1200] Loss_D: 0.290 Loss_G: 3.474 D(x): 0.849 D(G(z)): 0.089/0.050\n",
      "[16/50][601/1200] Loss_D: 0.489 Loss_G: 3.231 D(x): 0.880 D(G(z)): 0.262/0.058\n",
      "[17/50][1/1200] Loss_D: 0.617 Loss_G: 4.116 D(x): 0.894 D(G(z)): 0.291/0.025\n",
      "[17/50][601/1200] Loss_D: 0.594 Loss_G: 3.212 D(x): 0.865 D(G(z)): 0.269/0.067\n",
      "[18/50][1/1200] Loss_D: 0.509 Loss_G: 2.612 D(x): 0.817 D(G(z)): 0.200/0.097\n",
      "[18/50][601/1200] Loss_D: 0.634 Loss_G: 4.054 D(x): 0.827 D(G(z)): 0.278/0.027\n",
      "[19/50][1/1200] Loss_D: 0.318 Loss_G: 4.003 D(x): 0.914 D(G(z)): 0.168/0.028\n",
      "[19/50][601/1200] Loss_D: 0.449 Loss_G: 2.713 D(x): 0.750 D(G(z)): 0.101/0.089\n",
      "[20/50][1/1200] Loss_D: 0.389 Loss_G: 3.423 D(x): 0.855 D(G(z)): 0.178/0.052\n",
      "[20/50][601/1200] Loss_D: 0.257 Loss_G: 3.749 D(x): 0.952 D(G(z)): 0.163/0.035\n",
      "[21/50][1/1200] Loss_D: 0.367 Loss_G: 3.283 D(x): 0.821 D(G(z)): 0.089/0.060\n",
      "[21/50][601/1200] Loss_D: 0.435 Loss_G: 3.659 D(x): 0.799 D(G(z)): 0.127/0.046\n",
      "[22/50][1/1200] Loss_D: 0.509 Loss_G: 2.391 D(x): 0.689 D(G(z)): 0.071/0.155\n",
      "[22/50][601/1200] Loss_D: 1.037 Loss_G: 5.689 D(x): 0.869 D(G(z)): 0.472/0.006\n",
      "[23/50][1/1200] Loss_D: 0.388 Loss_G: 3.692 D(x): 0.888 D(G(z)): 0.189/0.039\n",
      "[23/50][601/1200] Loss_D: 0.357 Loss_G: 4.870 D(x): 0.934 D(G(z)): 0.194/0.014\n",
      "[24/50][1/1200] Loss_D: 0.663 Loss_G: 4.214 D(x): 0.956 D(G(z)): 0.396/0.023\n",
      "[24/50][601/1200] Loss_D: 0.431 Loss_G: 3.198 D(x): 0.745 D(G(z)): 0.072/0.078\n",
      "[25/50][1/1200] Loss_D: 0.884 Loss_G: 5.485 D(x): 0.882 D(G(z)): 0.445/0.008\n",
      "[25/50][601/1200] Loss_D: 0.470 Loss_G: 2.844 D(x): 0.837 D(G(z)): 0.172/0.089\n",
      "[26/50][1/1200] Loss_D: 0.457 Loss_G: 3.928 D(x): 0.983 D(G(z)): 0.270/0.036\n",
      "[26/50][601/1200] Loss_D: 0.356 Loss_G: 4.621 D(x): 0.888 D(G(z)): 0.149/0.019\n",
      "[27/50][1/1200] Loss_D: 0.282 Loss_G: 3.804 D(x): 0.967 D(G(z)): 0.190/0.040\n",
      "[27/50][601/1200] Loss_D: 0.286 Loss_G: 3.609 D(x): 0.882 D(G(z)): 0.087/0.050\n",
      "[28/50][1/1200] Loss_D: 0.471 Loss_G: 5.144 D(x): 0.969 D(G(z)): 0.289/0.009\n",
      "[28/50][601/1200] Loss_D: 0.213 Loss_G: 4.398 D(x): 0.882 D(G(z)): 0.056/0.023\n",
      "[29/50][1/1200] Loss_D: 0.800 Loss_G: 4.451 D(x): 0.910 D(G(z)): 0.373/0.023\n",
      "[29/50][601/1200] Loss_D: 0.286 Loss_G: 4.590 D(x): 0.957 D(G(z)): 0.177/0.017\n",
      "[30/50][1/1200] Loss_D: 0.230 Loss_G: 3.937 D(x): 0.870 D(G(z)): 0.065/0.033\n",
      "[30/50][601/1200] Loss_D: 0.336 Loss_G: 4.472 D(x): 0.915 D(G(z)): 0.186/0.018\n",
      "[31/50][1/1200] Loss_D: 0.175 Loss_G: 3.593 D(x): 0.950 D(G(z)): 0.108/0.039\n",
      "[31/50][601/1200] Loss_D: 0.323 Loss_G: 3.832 D(x): 0.934 D(G(z)): 0.176/0.032\n",
      "[32/50][1/1200] Loss_D: 0.470 Loss_G: 4.125 D(x): 0.828 D(G(z)): 0.134/0.037\n",
      "[32/50][601/1200] Loss_D: 0.281 Loss_G: 3.987 D(x): 0.907 D(G(z)): 0.106/0.037\n",
      "[33/50][1/1200] Loss_D: 0.290 Loss_G: 3.993 D(x): 0.851 D(G(z)): 0.080/0.038\n",
      "[33/50][601/1200] Loss_D: 0.375 Loss_G: 2.765 D(x): 0.800 D(G(z)): 0.069/0.145\n",
      "[34/50][1/1200] Loss_D: 0.120 Loss_G: 4.365 D(x): 0.943 D(G(z)): 0.053/0.034\n",
      "[34/50][601/1200] Loss_D: 0.101 Loss_G: 5.254 D(x): 0.956 D(G(z)): 0.048/0.010\n",
      "[35/50][1/1200] Loss_D: 0.531 Loss_G: 3.105 D(x): 0.812 D(G(z)): 0.173/0.076\n",
      "[35/50][601/1200] Loss_D: 0.634 Loss_G: 6.807 D(x): 0.940 D(G(z)): 0.341/0.002\n",
      "[36/50][1/1200] Loss_D: 0.617 Loss_G: 4.904 D(x): 0.986 D(G(z)): 0.370/0.013\n",
      "[36/50][601/1200] Loss_D: 0.257 Loss_G: 3.945 D(x): 0.964 D(G(z)): 0.168/0.032\n",
      "[37/50][1/1200] Loss_D: 0.372 Loss_G: 2.650 D(x): 0.790 D(G(z)): 0.061/0.134\n",
      "[37/50][601/1200] Loss_D: 0.815 Loss_G: 6.490 D(x): 0.993 D(G(z)): 0.406/0.003\n",
      "[38/50][1/1200] Loss_D: 0.329 Loss_G: 3.505 D(x): 0.849 D(G(z)): 0.120/0.052\n",
      "[38/50][601/1200] Loss_D: 0.237 Loss_G: 5.130 D(x): 0.878 D(G(z)): 0.082/0.014\n",
      "[39/50][1/1200] Loss_D: 0.312 Loss_G: 4.551 D(x): 0.939 D(G(z)): 0.159/0.021\n",
      "[39/50][601/1200] Loss_D: 0.287 Loss_G: 3.794 D(x): 0.831 D(G(z)): 0.058/0.043\n",
      "[40/50][1/1200] Loss_D: 0.443 Loss_G: 3.185 D(x): 0.736 D(G(z)): 0.039/0.074\n",
      "[40/50][601/1200] Loss_D: 0.644 Loss_G: 2.253 D(x): 0.682 D(G(z)): 0.146/0.147\n",
      "[41/50][1/1200] Loss_D: 0.861 Loss_G: 6.202 D(x): 0.981 D(G(z)): 0.384/0.004\n",
      "[41/50][601/1200] Loss_D: 0.133 Loss_G: 5.226 D(x): 0.937 D(G(z)): 0.058/0.012\n",
      "[42/50][1/1200] Loss_D: 0.332 Loss_G: 4.883 D(x): 0.778 D(G(z)): 0.020/0.035\n",
      "[42/50][601/1200] Loss_D: 0.268 Loss_G: 4.953 D(x): 0.907 D(G(z)): 0.095/0.018\n",
      "[43/50][1/1200] Loss_D: 0.126 Loss_G: 4.528 D(x): 0.984 D(G(z)): 0.091/0.020\n",
      "[43/50][601/1200] Loss_D: 0.394 Loss_G: 3.949 D(x): 0.799 D(G(z)): 0.064/0.047\n",
      "[44/50][1/1200] Loss_D: 0.205 Loss_G: 4.388 D(x): 0.979 D(G(z)): 0.144/0.020\n",
      "[44/50][601/1200] Loss_D: 0.176 Loss_G: 4.124 D(x): 0.921 D(G(z)): 0.075/0.040\n",
      "[45/50][1/1200] Loss_D: 0.184 Loss_G: 4.517 D(x): 0.887 D(G(z)): 0.045/0.029\n",
      "[45/50][601/1200] Loss_D: 0.142 Loss_G: 5.336 D(x): 0.983 D(G(z)): 0.095/0.012\n",
      "[46/50][1/1200] Loss_D: 0.099 Loss_G: 6.298 D(x): 0.949 D(G(z)): 0.038/0.008\n",
      "[46/50][601/1200] Loss_D: 0.247 Loss_G: 4.639 D(x): 0.863 D(G(z)): 0.061/0.027\n",
      "[47/50][1/1200] Loss_D: 0.123 Loss_G: 4.690 D(x): 0.906 D(G(z)): 0.013/0.022\n",
      "[47/50][601/1200] Loss_D: 0.272 Loss_G: 5.089 D(x): 0.920 D(G(z)): 0.117/0.014\n",
      "[48/50][1/1200] Loss_D: 0.272 Loss_G: 4.743 D(x): 0.861 D(G(z)): 0.066/0.032\n",
      "[48/50][601/1200] Loss_D: 0.185 Loss_G: 4.370 D(x): 0.908 D(G(z)): 0.067/0.030\n",
      "[49/50][1/1200] Loss_D: 0.492 Loss_G: 2.995 D(x): 0.681 D(G(z)): 0.021/0.115\n",
      "[49/50][601/1200] Loss_D: 0.219 Loss_G: 5.554 D(x): 0.850 D(G(z)): 0.021/0.015\n",
      "[50/50][1/1200] Loss_D: 0.301 Loss_G: 4.181 D(x): 0.966 D(G(z)): 0.201/0.028\n",
      "[50/50][601/1200] Loss_D: 0.262 Loss_G: 4.693 D(x): 0.860 D(G(z)): 0.066/0.021\n"
     ]
    }
   ],
   "source": [
    "# 学習のループ\n",
    "for epoch in range(n_epoch):\n",
    "    for itr, data in enumerate(dataloader):\n",
    "        real_image = data[0].to(device)\n",
    "        real_label = data[1].to(device)\n",
    "        real_image_label = concat_image_label(real_image, real_label, device) \n",
    "        sample_size = real_image.size(0)\n",
    "        noise = torch.randn(sample_size, nz, 1, 1, device = device)\n",
    "        fake_label = torch.randint(10, (sample_size,), dtype = torch.long, device = device)\n",
    "        fake_noise_label = concat_noise_label(noise, fake_label, device)        \n",
    "        real_target = torch.full((sample_size,), 1., device = device)\n",
    "        fake_target = torch.full((sample_size,), 0., device = device)\n",
    "        \n",
    "        ############################\n",
    "        # 識別器Dの更新\n",
    "        ###########################\n",
    "        Dnet.zero_grad()    \n",
    "        \n",
    "        output = Dnet(real_image_label)\n",
    "        errD_real = criterion(output, real_target)\n",
    "\n",
    "        D_x = output.mean().item()\n",
    "\n",
    "        fake_image = Gnet(fake_noise_label)\n",
    "        fake_image_label = concat_image_label(fake_image, fake_label, device)   \n",
    "        \n",
    "        output = Dnet(fake_image_label.detach()) \n",
    "        errD_fake = criterion(output, fake_target)  \n",
    "        D_G_z1 = output.mean().item()\n",
    "\n",
    "        errD = errD_real + errD_fake\n",
    "        errD.backward() \n",
    "        optimizerD.step() \n",
    "\n",
    "        ############################\n",
    "        # 生成器Gの更新\n",
    "        ###########################\n",
    "        Gnet.zero_grad()\n",
    "        \n",
    "        output = Dnet(fake_image_label)\n",
    "        errG = criterion(output, real_target) \n",
    "        errG.backward() \n",
    "        D_G_z2 = output.mean().item()\n",
    "\n",
    "        optimizerG.step() \n",
    "\n",
    "        if itr % display_interval == 0: \n",
    "            print('[{}/{}][{}/{}] Loss_D: {:.3f} Loss_G: {:.3f} D(x): {:.3f} D(G(z)): {:.3f}/{:.3f}'\n",
    "                  .format(epoch + 1, n_epoch,\n",
    "                          itr + 1, len(dataloader),\n",
    "                          errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
    "            \n",
    "        if epoch == 0 and itr == 0: \n",
    "            vutils.save_image(real_image, '{}/real_samples.png'.format(outf),\n",
    "                              normalize=True, nrow=10)\n",
    "\n",
    "    ############################\n",
    "    # 確認用画像の生成\n",
    "    ############################\n",
    "    fake_image = Gnet(fixed_noise_label)  \n",
    "    vutils.save_image(fake_image.detach(), '{}/fake_samples_epoch_{:03d}.png'.format(outf, epoch + 1),\n",
    "                      normalize=True, nrow=10)\n",
    "\n",
    "    ############################\n",
    "    # モデルの保存\n",
    "    ############################\n",
    "    if (epoch + 1) % 10 == 0:   \n",
    "        torch.save(Gnet.state_dict(), '{}/Gnet_epoch_{}.pth'.format(outf, epoch + 1))\n",
    "        torch.save(Dnet.state_dict(), '{}/Dnet_epoch_{}.pth'.format(outf, epoch + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "81284733",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"./grad_img\"):\n",
    "    os.mkdir(\"./grad_img\")\n",
    "from torchvision.utils import save_image\n",
    "import glob\n",
    "from PIL import Image\n",
    "\n",
    "def concat_noise_label(noise, label1,label2,weight, device):\n",
    "    oh_label1 = onehot_encode(label1, device)\n",
    "    oh_label2 = onehot_encode(label2, device)\n",
    "    oh_label = weight * oh_label1 + (1 - weight) * oh_label2\n",
    "    return torch.cat((noise, oh_label), dim = 1) \n",
    "    \n",
    "gradation = 100\n",
    "noise = torch.randn(1, nz, 1, 1, device = device)\n",
    "for i in range(gradation):\n",
    "    weight = i / gradation\n",
    "    fake_noise_label = concat_noise_label(noise, 6, 9, weight, device)\n",
    "    out = Gnet(fake_noise_label)\n",
    "    save_image(out, \"./grad_img/{:03d}.jpg\".format(i))\n",
    "    \n",
    "files = sorted(glob.glob('./grad_img/*.jpg'))  \n",
    "images = list(map(lambda file : Image.open(file) , files))\n",
    "images[0].save('generating_process.gif' , save_all = True , append_images = images[1:] , duration = 100 , loop = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa2422c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
