{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cf8d87-f772-447b-a039-8a3b62d6ba88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn,optim\n",
    "from torch.utils.data import Dataset,TensorDataset,DataLoader\n",
    "import tqdm\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45538953-b14f-450a-b720-a7395b81c9bd",
   "metadata": {},
   "source": [
    "### imageの準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b477d5-7972-4bab-8d46-86cfa603f4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget http://www.robots.ox.ac.uk/~vgg/data/flowers/102/102flowers.tgz\n",
    "!tar xf 102flowers.tgz\n",
    "!mkdir oxford-102\n",
    "!mkdir oxford-102/jpg\n",
    "!mv jpg/*.jpg oxford-102/jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc077f52-9e57-45fb-80c4-e4144ba49665",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_data=ImageFolder(\"./oxford-102/\",\n",
    "                     transform=transforms.Compose([transforms.Resize(80),transforms.CenterCrop(64),transforms.ToTensor()]))\n",
    "batch_size=64\n",
    "img_loader=DataLoader(img_data,batch_size=batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b115f28e-3857-4b1e-b3f1-90fe02ecf272",
   "metadata": {
    "tags": []
   },
   "source": [
    "### GnetとDnetの定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f0ddd1-c995-4813-8930-15aa42d7bedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "nz=100\n",
    "ngf=32\n",
    "\n",
    "class GNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.main=nn.Sequential(\n",
    "            nn.ConvTranspose2d(nz,ngf*8,4,1,0,bias=False),\n",
    "            nn.BatchNorm2d(ngf*8),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(ngf*8,ngf*4,4,2,1,bias=False),\n",
    "            nn.BatchNorm2d(ngf*4),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(ngf*4,ngf*2,4,2,1,bias=False),\n",
    "            nn.BatchNorm2d(ngf*2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(ngf*2,ngf*1,4,2,1,bias=False),\n",
    "            nn.BatchNorm2d(ngf*1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(ngf*1,3,4,2,1,bias=True),\n",
    "            nn.Tanh()\n",
    "            )\n",
    "\n",
    "    def forward(self,x):\n",
    "        out=self.main(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d042fdc-262d-4fc2-96f6-fde8d6767eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndf=32\n",
    "\n",
    "class DNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.main=nn.Sequential(\n",
    "            nn.Conv2d(3,ndf,4,2,1,bias=False),\n",
    "            nn.LeakyReLU(0.2,inplace=True),\n",
    "            nn.Conv2d(ndf,ndf*2,4,2,1,bias=False),\n",
    "            nn.BatchNorm2d(ndf*2),\n",
    "            nn.LeakyReLU(0.2,inplace=True),\n",
    "            nn.Conv2d(ndf*2,ndf*4,4,2,1,bias=False),\n",
    "            nn.BatchNorm2d(ndf*4),\n",
    "            nn.LeakyReLU(0.2,inplace=True),\n",
    "            nn.Conv2d(ndf*4,ndf*8,4,2,1,bias=False),\n",
    "            nn.BatchNorm2d(ndf*8),\n",
    "            nn.LeakyReLU(0.2,inplace=True),\n",
    "            nn.Conv2d(ndf*8,1,4,1,0,bias=True)\n",
    "            )\n",
    "\n",
    "    def forward(self,x):\n",
    "        out=self.main(x)\n",
    "        return out.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830b5741-8f24-4dec-ab8b-65ed7b905dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "d=DNet().to(\"cuda:0\")\n",
    "g=GNet().to(\"cuda:0\")\n",
    "\n",
    "opt_d=optim.Adam(d.parameters(),lr=0.0002,betas=(0.5,0.999))\n",
    "opt_g=optim.Adam(g.parameters(),lr=0.0002,betas=(0.5,0.999))\n",
    "\n",
    "ones=torch.ones(batch_size).to(\"cuda:0\")\n",
    "zeros=torch.zeros(batch_size).to(\"cuda:0\")\n",
    "\n",
    "loss_f=nn.BCEWithLogitsLoss()\n",
    "\n",
    "fixed_z=torch.randn(batch_size,nz,1,1).to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9490ca48-2b15-4552-98d9-5c21fd7c4672",
   "metadata": {},
   "source": [
    "### 訓練関数の定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6b3bbd-8375-433f-af8c-a28680dbe385",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean\n",
    "\n",
    "def train_dcgan(g,d,opt_g,opt_d,loader):\n",
    "    log_loss_g=[]\n",
    "    log_loss_d=[]\n",
    "    for real_img,_ in tqdm.tqdm(loader):\n",
    "        batch_len=len(real_img)\n",
    "        real_img=real_img.to(\"cuda:0\")\n",
    "        z=torch.randn(batch_len,nz,1,1).to(\"cuda:0\")\n",
    "        #fake_img=g.forward(z)\n",
    "        fake_img=g(z)\n",
    "        fake_img_tensor=fake_img.detach()\n",
    "        out=d.forward(fake_img)\n",
    "        loss_g=loss_f(out,ones[:batch_len])\n",
    "        log_loss_g.append(loss_g.item())\n",
    "        d.zero_grad(),g.zero_grad()\n",
    "        loss_g.backward()\n",
    "        opt_g.step()\n",
    "        real_out=d.forward(real_img)\n",
    "        loss_d_real=loss_f(real_out,ones[:batch_len])\n",
    "\n",
    "        fake_img=fake_img_tensor\n",
    "        fake_out=d.forward(fake_img_tensor)\n",
    "        loss_d_fake=loss_f(fake_out,zeros[:batch_len])\n",
    "\n",
    "        loss_d=loss_d_real+loss_d_fake\n",
    "        log_loss_d.append(loss_d.item())\n",
    "        d.zero_grad(),g.zero_grad()\n",
    "        loss_d.backward()\n",
    "        opt_d.step()\n",
    "\n",
    "    return mean(log_loss_g),mean(log_loss_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d5f3ae-fa76-4064-9a36-471510531db2",
   "metadata": {},
   "source": [
    "### 訓練開始"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2f7585-ce94-4f0d-87e6-36626bdd625d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if !os.path.exists(\"data\"):\n",
    "    os.mkdir(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcb1e2d-58c2-411c-bca8-9987906203cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_time=0.0\n",
    "average_time=0.0\n",
    "iter_epoch=300\n",
    "for epoch in range(iter_epoch):\n",
    "    t_start=time.time()\n",
    "    print(epoch)\n",
    "    train_dcgan(g,d,opt_g,opt_d,img_loader)\n",
    "    t_finish=time.time()\n",
    "    total_time+=t_finish-t_start\n",
    "    average_time=total_time/(epoch+1)\n",
    "    print(\"runtime = \",t_finish-t_start,\"sec\")\n",
    "    print(\"expected remaining time = \",average_time*(iter_epoch-(epoch+1)),\"sec\",\":\",average_time*(iter_epoch-(epoch+1))/60,\"minute\")\n",
    "    if epoch%10==0:\n",
    "        torch.save(g.state_dict(),\"./data/g_{:03d}.prm\".format(epoch),pickle_protocol=4)\n",
    "        torch.save(d.state_dict(),\"./data/d_{:03d}.prm\".format(epoch),pickle_protocol=4)\n",
    "        generated_img=g(fixed_z)\n",
    "        save_image(generated_img,\"./data/{:03d}.jpg\".format(epoch))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
