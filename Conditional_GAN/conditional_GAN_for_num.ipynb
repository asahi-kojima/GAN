{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a12a8978",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d63c7f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "workers = 2\n",
    "batch_size=50\n",
    "nz = 100\n",
    "nch_g = 128\n",
    "nch_d = 128\n",
    "n_epoch = 15\n",
    "lr = 0.0002\n",
    "beta1 = 0.5\n",
    "outf = './result_cgan'\n",
    "display_interval = 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "866dc748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6889666",
   "metadata": {},
   "source": [
    "### MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7e37dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, ), (0.5, ))])\n",
    "dataset = datasets.MNIST(root='./data', \n",
    "                                        train=True,\n",
    "                                        download=True,\n",
    "                                        transform=transform)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size = batch_size, shuffle = True, num_workers = int(workers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b1dbbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, nz = 100,  nch_g = 64, nch = 1):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "                nn.ConvTranspose2d(nz, nch_g * 4, 3, 1, 0),    \n",
    "                nn.BatchNorm2d(nch_g * 4),                      \n",
    "                nn.ReLU(),\n",
    "                nn.ConvTranspose2d(nch_g * 4, nch_g * 2, 3, 2, 0),\n",
    "                nn.BatchNorm2d(nch_g * 2),\n",
    "                nn.ReLU(),\n",
    "                nn.ConvTranspose2d(nch_g * 2, nch_g, 4, 2, 1),\n",
    "                nn.BatchNorm2d(nch_g),\n",
    "                nn.ReLU(),\n",
    "                nn.ConvTranspose2d(nch_g, nch, 4, 2, 1),\n",
    "                nn.Tanh()\n",
    "                )\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.layers(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03c0ab23",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, nch=1, nch_d=64):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "                nn.Conv2d(nch, nch_d, 4, 2, 1),     # 畳み込み\n",
    "                nn.LeakyReLU(negative_slope=0.2),\n",
    "                nn.Conv2d(nch_d, nch_d * 2, 4, 2, 1),\n",
    "                nn.BatchNorm2d(nch_d * 2),\n",
    "                nn.LeakyReLU(negative_slope=0.2),\n",
    "                nn.Conv2d(nch_d * 2, nch_d * 4, 3, 2, 0),\n",
    "                nn.BatchNorm2d(nch_d * 4),\n",
    "                nn.LeakyReLU(negative_slope=0.2),\n",
    "                nn.Conv2d(nch_d * 4, 1, 3, 1, 0),\n",
    "                nn.Sigmoid()\n",
    "                ) \n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f86b85a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator(\n",
      "  (layers): Sequential(\n",
      "    (0): ConvTranspose2d(110, 512, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): ConvTranspose2d(512, 256, kernel_size=(3, 3), stride=(2, 2))\n",
      "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU()\n",
      "    (6): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (8): ReLU()\n",
      "    (9): ConvTranspose2d(128, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (10): Tanh()\n",
      "  )\n",
      ")\n",
      "Discriminator(\n",
      "  (layers): Sequential(\n",
      "    (0): Conv2d(11, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (1): LeakyReLU(negative_slope=0.2)\n",
      "    (2): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): LeakyReLU(negative_slope=0.2)\n",
      "    (5): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2))\n",
      "    (6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): LeakyReLU(negative_slope=0.2)\n",
      "    (8): Conv2d(512, 1, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (9): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "Gnet = Generator(nz = nz+10, nch_g = nch_g).to(device)\n",
    "Dnet = Discriminator(nch = 1+10, nch_d = nch_d).to(device)\n",
    "print(Gnet)\n",
    "print(Dnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6876b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizerD = optim.Adam(Dnet.parameters(), lr=lr, betas=(beta1, 0.999), weight_decay=1e-5)\n",
    "optimizerG = optim.Adam(Gnet.parameters(), lr=lr, betas=(beta1, 0.999), weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "860a0366",
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot_encode(label, device, n_class = 10):\n",
    "    eye = torch.eye(n_class, device = device)\n",
    "    return eye[label].view(-1, n_class, 1, 1) \n",
    "\n",
    "def concat_image_label(image, label, device, n_class=10):\n",
    "    B, C, H, W = image.shape\n",
    "    \n",
    "    oh_label = onehot_encode(label, device)\n",
    "    oh_label = oh_label.expand(B, n_class, H, W)\n",
    "    return torch.cat((image, oh_label), dim = 1)\n",
    "\n",
    "def concat_noise_label(noise, label, device):\n",
    "    oh_label = onehot_encode(label, device) \n",
    "    return torch.cat((noise, oh_label), dim = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4bad0b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 100, 1, 1])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3,\n",
      "        4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7,\n",
      "        8, 9], device='cuda:0')\n",
      "torch.Size([50, 110, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "fixed_noise = torch.randn(batch_size, nz, 1, 1, device=device)\n",
    "fixed_label = [i for i in range(10)] * (batch_size // 10)\n",
    "fixed_label = torch.tensor(fixed_label, dtype=torch.long, device=device)\n",
    "fixed_noise_label = concat_noise_label(fixed_noise, fixed_label, device) \n",
    "print(fixed_noise.shape)\n",
    "print(fixed_label)\n",
    "print(fixed_noise_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76985943",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(outf):\n",
    "    os.mkdir(outf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0aadfad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/15][1/1200] Loss_D: 1.480 Loss_G: 1.252 D(x): 0.491 D(G(z)): 0.522/0.296\n",
      "[1/15][601/1200] Loss_D: 0.641 Loss_G: 2.058 D(x): 0.688 D(G(z)): 0.182/0.166\n",
      "[2/15][1/1200] Loss_D: 1.181 Loss_G: 1.375 D(x): 0.489 D(G(z)): 0.306/0.281\n",
      "[2/15][601/1200] Loss_D: 1.651 Loss_G: 1.158 D(x): 0.694 D(G(z)): 0.686/0.341\n",
      "[3/15][1/1200] Loss_D: 0.920 Loss_G: 1.424 D(x): 0.552 D(G(z)): 0.237/0.267\n",
      "[3/15][601/1200] Loss_D: 0.858 Loss_G: 1.675 D(x): 0.573 D(G(z)): 0.218/0.212\n",
      "[4/15][1/1200] Loss_D: 1.210 Loss_G: 1.502 D(x): 0.799 D(G(z)): 0.600/0.237\n",
      "[4/15][601/1200] Loss_D: 0.909 Loss_G: 1.070 D(x): 0.662 D(G(z)): 0.361/0.358\n",
      "[5/15][1/1200] Loss_D: 1.420 Loss_G: 0.715 D(x): 0.368 D(G(z)): 0.287/0.514\n",
      "[5/15][601/1200] Loss_D: 1.936 Loss_G: 0.984 D(x): 0.367 D(G(z)): 0.555/0.400\n",
      "[6/15][1/1200] Loss_D: 0.751 Loss_G: 1.018 D(x): 0.659 D(G(z)): 0.259/0.387\n",
      "[6/15][601/1200] Loss_D: 0.713 Loss_G: 1.758 D(x): 0.641 D(G(z)): 0.199/0.197\n",
      "[7/15][1/1200] Loss_D: 1.143 Loss_G: 1.450 D(x): 0.724 D(G(z)): 0.506/0.260\n",
      "[7/15][601/1200] Loss_D: 0.813 Loss_G: 1.688 D(x): 0.760 D(G(z)): 0.384/0.204\n",
      "[8/15][1/1200] Loss_D: 1.225 Loss_G: 1.778 D(x): 0.951 D(G(z)): 0.648/0.197\n",
      "[8/15][601/1200] Loss_D: 1.341 Loss_G: 1.491 D(x): 0.663 D(G(z)): 0.545/0.248\n",
      "[9/15][1/1200] Loss_D: 1.130 Loss_G: 1.092 D(x): 0.464 D(G(z)): 0.230/0.370\n",
      "[9/15][601/1200] Loss_D: 1.183 Loss_G: 1.101 D(x): 0.487 D(G(z)): 0.290/0.365\n",
      "[10/15][1/1200] Loss_D: 1.176 Loss_G: 1.702 D(x): 0.618 D(G(z)): 0.440/0.209\n",
      "[10/15][601/1200] Loss_D: 0.827 Loss_G: 1.475 D(x): 0.878 D(G(z)): 0.460/0.253\n",
      "[11/15][1/1200] Loss_D: 1.151 Loss_G: 1.569 D(x): 0.560 D(G(z)): 0.381/0.229\n",
      "[11/15][601/1200] Loss_D: 1.081 Loss_G: 2.249 D(x): 0.708 D(G(z)): 0.458/0.130\n",
      "[12/15][1/1200] Loss_D: 0.767 Loss_G: 1.661 D(x): 0.821 D(G(z)): 0.394/0.221\n",
      "[12/15][601/1200] Loss_D: 0.484 Loss_G: 2.199 D(x): 0.760 D(G(z)): 0.162/0.141\n",
      "[13/15][1/1200] Loss_D: 0.713 Loss_G: 1.643 D(x): 0.600 D(G(z)): 0.136/0.217\n",
      "[13/15][601/1200] Loss_D: 1.219 Loss_G: 2.274 D(x): 0.696 D(G(z)): 0.502/0.125\n",
      "[14/15][1/1200] Loss_D: 1.295 Loss_G: 1.956 D(x): 0.773 D(G(z)): 0.579/0.162\n",
      "[14/15][601/1200] Loss_D: 0.684 Loss_G: 2.265 D(x): 0.751 D(G(z)): 0.278/0.123\n",
      "[15/15][1/1200] Loss_D: 0.683 Loss_G: 2.737 D(x): 0.841 D(G(z)): 0.364/0.081\n",
      "[15/15][601/1200] Loss_D: 0.709 Loss_G: 1.813 D(x): 0.692 D(G(z)): 0.242/0.189\n"
     ]
    }
   ],
   "source": [
    "# 学習のループ\n",
    "for epoch in range(n_epoch):\n",
    "    for itr, data in enumerate(dataloader):\n",
    "        real_image = data[0].to(device)\n",
    "        real_label = data[1].to(device)\n",
    "        real_image_label = concat_image_label(real_image, real_label, device) \n",
    "        sample_size = real_image.size(0)\n",
    "        noise = torch.randn(sample_size, nz, 1, 1, device = device)\n",
    "        fake_label = torch.randint(10, (sample_size,), dtype = torch.long, device = device)\n",
    "        fake_noise_label = concat_noise_label(noise, fake_label, device)        \n",
    "        real_target = torch.full((sample_size,), 1., device = device)\n",
    "        fake_target = torch.full((sample_size,), 0., device = device)\n",
    "        \n",
    "        ############################\n",
    "        # 識別器Dの更新\n",
    "        ###########################\n",
    "        Dnet.zero_grad()    \n",
    "        \n",
    "        output = Dnet(real_image_label)\n",
    "        errD_real = criterion(output, real_target)\n",
    "\n",
    "        D_x = output.mean().item()\n",
    "\n",
    "        fake_image = Gnet(fake_noise_label)\n",
    "        fake_image_label = concat_image_label(fake_image, fake_label, device)   \n",
    "        \n",
    "        output = Dnet(fake_image_label.detach()) \n",
    "        errD_fake = criterion(output, fake_target)  \n",
    "        D_G_z1 = output.mean().item()\n",
    "\n",
    "        errD = errD_real + errD_fake\n",
    "        errD.backward() \n",
    "        optimizerD.step() \n",
    "\n",
    "        ############################\n",
    "        # 生成器Gの更新\n",
    "        ###########################\n",
    "        Gnet.zero_grad()\n",
    "        \n",
    "        output = Dnet(fake_image_label)\n",
    "        errG = criterion(output, real_target) \n",
    "        errG.backward() \n",
    "        D_G_z2 = output.mean().item()\n",
    "\n",
    "        optimizerG.step() \n",
    "\n",
    "        if itr % display_interval == 0: \n",
    "            print('[{}/{}][{}/{}] Loss_D: {:.3f} Loss_G: {:.3f} D(x): {:.3f} D(G(z)): {:.3f}/{:.3f}'\n",
    "                  .format(epoch + 1, n_epoch,\n",
    "                          itr + 1, len(dataloader),\n",
    "                          errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
    "            \n",
    "        if epoch == 0 and itr == 0: \n",
    "            vutils.save_image(real_image, '{}/real_samples.png'.format(outf),\n",
    "                              normalize=True, nrow=10)\n",
    "\n",
    "    ############################\n",
    "    # 確認用画像の生成\n",
    "    ############################\n",
    "    fake_image = Gnet(fixed_noise_label)  \n",
    "    vutils.save_image(fake_image.detach(), '{}/fake_samples_epoch_{:03d}.png'.format(outf, epoch + 1),\n",
    "                      normalize=True, nrow=10)\n",
    "\n",
    "    ############################\n",
    "    # モデルの保存\n",
    "    ############################\n",
    "    if (epoch + 1) % 10 == 0:   \n",
    "        torch.save(Gnet.state_dict(), '{}/Gnet_epoch_{}.pth'.format(outf, epoch + 1))\n",
    "        torch.save(Dnet.state_dict(), '{}/Dnet_epoch_{}.pth'.format(outf, epoch + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "81284733",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"./grad_img\"):\n",
    "    os.mkdir(\"./grad_img\")\n",
    "from torchvision.utils import save_image\n",
    "import glob\n",
    "from PIL import Image\n",
    "\n",
    "def concat_noise_label(noise, label1,label2,weight, device):\n",
    "    oh_label1 = onehot_encode(label1, device)\n",
    "    oh_label2 = onehot_encode(label2, device)\n",
    "    oh_label = weight * oh_label1 + (1 - weight) * oh_label2\n",
    "    return torch.cat((noise, oh_label), dim = 1) \n",
    "    \n",
    "gradation = 100\n",
    "noise = torch.randn(1, nz, 1, 1, device = device)\n",
    "for i in range(gradation):\n",
    "    weight = i / gradation\n",
    "    fake_noise_label = concat_noise_label(noise, 9, 6, weight, device)\n",
    "    out = Gnet(fake_noise_label)\n",
    "    save_image(out, \"./grad_img/{:03d}.jpg\".format(i))\n",
    "    \n",
    "files = sorted(glob.glob('./grad_img/*.jpg'))  \n",
    "images = list(map(lambda file : Image.open(file) , files))\n",
    "images[0].save('generating_process.gif' , save_all = True , append_images = images[1:] , duration = 100 , loop = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa2422c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9194fce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
